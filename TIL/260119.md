# 데이터분석을 위한 머신러닝 알고리즘

## 챕터
- 선형 변환 및 행렬 연산
- Regression
- 베이즈 정리, 나이브 베이즈
- Classif
- KNN

## 선형 변환 및 행렬 연산 이론
- 행렬의 중요성
    - 데이터를 효율적으로 표현하고, 모델을 학습시키기 위해 행렬 사용
    - 데이터 표현: 대부분의 이미지는 행렬 형태로 저장
    - 머신러닝 알고리즘
    - 최적화 및 학습 과정

## 행렬의 기초
- 행렬 곱
    - 두개의 행렬을 곱하는 연산
    - 첫번째 행렬의 열개수와 두번째 행렬의 행 개수가 같아야 곱셈 가능
    - 1xn 행렬과 nX1 행렬의 곱으로 표현하는 형태를 백터의 내적이라 볼수 있음

- 전치 행렬
    - 행과 열을 바꾸는 연산


## 평행이동
- 선형 변환
    - 선형 변환은 한 백터 공간의 백터를 다른 백터로 대응시키는 변환
    - 크기조절, 회전, 대칭, 전단 같은 공간의 형태 변형을 표현
- 평행 이동
    - 공간의 모든 점을 같은 방향, 같은 거리만큼 이동


## Regression
- 회귀
    - 연속적인 숫자값을 예측하는 지도 학습의 한 유형
    - 입력 데이터를 기반으로 특정 연속적 목표 값을 예측하는 것이 목적
- 회귀 문제의 목표
    - 입력 변수를 사용하여 출력 값의 추세를 학습하고, 이를 기반으로 새로운 데이터에 대해 예측을 수행
- 회귀의 활용 예시
    - 주택 가격 예측: 집의 크기, 위치, 연도 등의 정보를 바탕으로 가격을 예측
- 회귀와 분류의 차이점
    - 회귀는 연속적인 값을 예측하는 문제
- 회귀 문제의 예시
    - 주택 가격 예측
    - 주식 시작 분석
    - 날시 예측 
    - 판매량 예측
- 입력 변수
    - 회귀 문제에서 입력 변수는 예측에 필요한 다양한 특성을 의미
- 출력 변수
    - 회귀 문제의 출력은 예측하고자 하는 연속적인 값
- 모델의 목적
    - 입력 변수와 출력 변수간의 관계를 학습해, 새로운 입력이 주어졌을대 적절한 출력 값을 예측
- 회귀의 종류
    - 단순 선형회귀: 한개의 독립변수로 종속 변수를 예측, 직선
    - 다중 선형회귀: 두개 이상의 독립변수로 종속변수를 예측, 3차원 이상에서 평면으로
    - 다항 회귀: 2차항 이상의 항으로 계산, 다항식
    - 로지스틱 회귀: 범주형 종속 변수를 예측하는 분류 모델

- 선형회귀란?
    - 입력 변수와 출력 변수간의 선형 관계를 가정하여 예측하는 모델
    - 장점: 해석이 용이하고 계산이 빠름
    - 단점: 입력 변수와 출력 변수 간의 관계가 비선형적일 경우 성능이 저하될 수 있음

- 다중회귀란?
    - 여러 개의 입력 변수를 사용하여 출력 변수를 예측하는 선형 회귀 모델

## 나이브 베이즈 분류

- 나이브 베이즈 분류
    - 각 특징들이 독립적이라는 가정 설정
    - 베이즈 정리를 활용한 확률 통계학적 분류 알고리즘

- 베이즈 정리
    - 사건 B가 발생했을 때, A도 같이 발생했을 확률

- 나이브 베이즈 분류
    - 베이즈 정리를 활용하여 입력값이 해당 클래스에 속할 확률을 계산하여 분류

## Classification 개론
- 분류의 정의
    - 분류는 입력데이터가 여러 개의 카테고리 중 하나에 속하도록 지정하는 직업
- 분류 문제의 목표
    - 학습 알고리즘은 함수 f을 생성하여 입력 벡터 x가 어떤 카테고리 y에 속하는지를 예측

- 분류와 회귀의 차이
    - 분류
        - 데이터를 미리 정의된 카테고리로 분류하는 작업
    - 회귀
        - 연속적인 숫자값을 예측하는 작업
    - 핵심 차이점
        - 분류는 결과가 '카테고리'로 나타나며, 이산적인 값으로 분류
        - 회귀 결과가 '숫자'로 나타나며, 연속적인 값을 예측

- 분류
    - Training Data를 이용해서 데이터의 특성과 상관관계 등을 파악
    - 입력 데이터
        - 분류 문제에서 입력 데이터는 하나 이상의 특징(Feature)으로 이루어진 백터 표현
    - 출력 데이터
        - 분류 문제의 출력은 데이터가 속한 클래스를 나타냄
    - 입력과 출력의 관계
        - 분류 모델은 주어진 입력 x에 대해 적절한 출력 y를 예측하는 함수 f(x)를 학습

- 결정 경계란?
    - 분류 모델이 데이터를 분류하기 위해 공간을 나누는 경계선
    - 입력 데이터를 특징 공간에서 서로 다른 클래스 영역으로 구분

- 결정 경계의 역할
    - 각 클래스에 속하는 데이터 포인트를 구분하는 기준을 제공
    - 새로운 데이터가 주어졌을 때, 그 데이터가 어느 클래스에 속하는지 결정

- 결정 경계의 예시
    - 선형 결정 경계: 단순한 직선이나 평면으로 클래스 간의 경계를 나눔
    - 비선형 결정 경계: 더 복잡한 경계를 만들어 클래스 간의 경계를 나눔

- 결정 경계 시각화
    - 2차원 특징 공간에서는 결정 경계를 쉽게 시각화 가능

### 로지스틱 회귀
- 로지스틱 회귀란
    - 이진 분류를 위한 대표적인 선형 모델
- 로지스틱 함수
    - 예측값을 0과 1사이의 확률로 변환하는 함수
- 장점
    - 해석이 간단하고 계산이 빠름
    - 데이터가 선형적으로 분리될 수 있는 경우 좋은 성능
- 단점
    - 비선형 데이터에는 적합하지 않을 수 있음
    - 복잡한 결정 경계를 만들기 어려움

- 결정 트리란
    - 데이터를 feature에 따라 트리 구조로 분활하여 분류하거나 예측하는 알고리즘
    - 작동방식
        - 특성 선택: 각 특성을 기준으로 데이터를 분할할 수 있는 최적의 조건을 찾음
        - 분할: 데이터를 해당 특성조건에 따라 좌우로 분기함
    - 특성 선택 기준
        - 지니 지수 또는 엔트로피를 사용하여 분할의 순도를 측정
        - 순도가 높을수록 해당되는 특성은 더 좋은 분할 기준

    - 장점
        - 해석이 용이: 트리 구조로 시각화가 가능하며, 결과 해석이 직관적
        - 비선형 데이터에도 적합: 복잡한 결정 경계를 만들 수 있음
        - 데이터 전처리 과정이 간단하며, 범주형 데이터도 다룰 수 있음
    
    - 단점
        - 트리가 너무 깊어지면 과적합의 위험이 있음
        - 작은 변화에도 모델이 민감하게 반응할 수 있음

    
## KNN
- k-최근접 이웃 알고리즘이란?
    - 지도 학습에서 사용되는 간단한 분류 알고리즘
    - 데이터 포인트가 주어졌을 때, 그 데이터와 가장 가까운 K개의 이웃을 기준으로 클래스 결정
- 작동방식
    - 거리계산: 새로운 데이터와 훈련 데이터 간의 거리를 계산
    - K개의 이웃 선택: 가장 가까운 K개의 이웃을 선택
    - 다수결 투표: 선택된 이웃 중 가장 많은 클래스에 속하는 클래스를 새로운 데이터의 클래스로 예측
- 장점
    - 직관적이고 이해하기 쉬움
    - 복잡한 결정 경계도 학습할 수 있음
- 단점
    - 데이터가 많아지면 계산 비용이 많이 듦
    - 차원의 저주에 취약함
- 사용 예시
    - 이미지 인식, 추천 시스템, 패턴 인식 등에서 사용